## Materials and Methods

### Lineage tree-based hidden Markov model

The core assumption of a Markov chain is that the next state and current observation (in our case cells) are only dependent on the current state. Proof of many of the expressions below can be found in prior work [@doi:10.1109/TSP.2004.832006]. With a lineage of cells and observations from each cell, we aim to use a lineage tree-based hidden Markov model to predict the specific states that each cell is in and the estimated phenotype distributions for each state. The tHMM is composed of several intermediate steps to carry out prediction and estimation.

#### Model flow

The initial probabilities of a cell being in state $k$ are represented by the vector $\pi$ that sums to 1:  
$$\pi_k = P(z_1 = k), \qquad k \in \{1, ..., K\}$$  
The probability of state $i$ transitioning to state $j$ is represented by the $K \times K$ matrix $T$ in which each row sums to 1:   
$$T_{i,j} = T(z_i \rightarrow z_j) = P(z_j \;| z_i), \qquad i,j \in \{1, ..., K\}$$  
The emission likelihood matrix $EL$ is based upon the cell observations. It is defined as the probability of an observation conditioned on the cell being in a specific state:  
$$EL(n,k) = P(x_n = x | z_n = k)$$

Separate emissions observations were assumed to be independent. Since the hidden states are unobserved, we applied an expectation-maximization (EM) algorithm, also called Baum-Welch for hidden Markov models. EM requires two steps: (1) the expectation (E) step in which given the whole tree, the probability of a cell and its parent being in specific states are calculated, so for every cell and every state we have $P(z_n = k \;| X_n)$ and $P(z_n = k,\; z_{n+1} = l \; | X_n)$, respectively. The E step is calculated using the upward and downward recursion algorithms. The second step is the M step, which fits the emissions distributions to the state-assigned cells. The process is repeated until convergence.

#### Upward and downward recursion

An _upward-downward_ algorithm for smoothed probabilities in tree hidden Markov model has been previously proposed to avoid underflow when calculating these two probability matrices [@doi:10.1109/TSP.2004.832006]. To explain we need to introduce the following definitions:

- $p(n)$ is noted as the parent cell of the cell $n$, and $c(n)$ is noted as children of cell $n$.
- $\bar{X}$ is the observation of the whole tree and $\bar{X}_a$ is a subtree of $\bar{X}$ which is rooted at cell $a$. Also, $\bar{Z}$ is the complete hidden state tree.
- $\bar{X}_{a/b}$ is the subtree rooted at $a$ except for the subtree rooted at cell $b$, if $\bar{X}_b$ is a subtree of $\bar{X}_a$.

For state prediction in tHMM model we start by calculating the marginal state distribution (MSD) matrix. MSD is an $N \times K$ matrix that for each cell is marginalizing the transition probability over all possible current states by downward traversing from root to leaf cells:  
$$MSD(n,k) = P(z_{n} = k)= \sum_{i} P(z_n = k |z_{n-1} = i)\times P(z_{n-1} = i)$$

During upward recursion, the flow of upward probabilities is calculated from leaf cells to the root cells generation by generation. For leaf cells, which are the base case to start with the $\beta$s are calculated by:  
$$\beta(n,k) = P(z_n = k\;|X_n = x_n) = \frac{EL(n,k) \times MSD(n,k)}{NF_l(n)}$$

in which $X_n$ is the leaf cell's observation, and NF (Normalizing Factor) is an $N \times 1$ matrix that is the marginal observation distribution. Since $\sum_{k} \beta_n(k) = 1$, we find the expression for NF for leaf cells is:  
$$NF_l(n) = \sum_{k} EL(n,k) \times MSD(n,k) = P(X_n = x_n)$$

For non-leaf cells the upward values are given by:  
$$ \beta(n,k) = P(z_n = k\;|\bar{X}_n = \bar{x}_n) = \frac{EL(n,k) \times MSD(n,k) \times \prod_{v \in c(n)}\beta_{n,v}(k)}{NF_{nl}(n)}$$

in which we can extract non-leaf NF such that:  
$$NF_{nl}(n) = \sum_{k} \Big[EL(n,k) \times MSD(n,k) \prod_{v \in c(n)} \beta_{n,v}(k)\Big]$$

and linking $\beta$ between parent-daughter cells is given by:  
$$ \beta_{p(n), n}(k) = P(\bar{X}_n = \bar{x}_n | z_{p(n)} = j) = \sum_{j} \frac{\beta_n(j) \times T_{k,j}}{MSD(n,j)}$$

By recursing from leaf cells to root cells, $\beta$ and NF matrices are calculated as upward recursion. Calculating the NF matrix gives a convenient expression for the log-likelihood of the observations. For the root cell we have:

$$P(\bar{X} = \bar{x}) = \prod_{n} \frac{P(\bar{X}_n = \bar{x}_n)}{\prod_{v\in c(n)} P(\bar{X}_v = \bar{x}_v)} = \sum_{n} NF(n) \qquad n \in \{1, ..., N\}$$

As a conclusion:  
$$log P(\bar{X} = \bar{x}) = \sum_{n} log NF(n)$$

This helps with keeping track of the log-likelihood which as a measure of convergence of the EM algorithm.

For computing downward recursion, we need the following definition starting from the root cells:  
$$ \gamma_1(k) = P(z_1 = k | \bar{X}_1 = \bar{x}_1) = \beta_1(k)$$

Other cells follow in a $N \times K$ matrix by writing the conditional probabilities as the summation over the joint probabilities of parent-daughter cells:  
$$\gamma_n(k) = P(z_n = k | \bar{X}_1 = \bar{x}_1) = \frac{\beta_n(k)}{MSD(n,k)} \sum_{i}\frac{T_{i,k} \gamma_{p(n)}(i)}{\beta_{p(n),n}(i)}$$

#### Viterbi algorithm

Given the sequence of observations in a hidden Markov chain the Viterbi algorithm is commonly used to find the most likely sequence of states. Equivalently, here it returns the most likely sequence of states of the cells in a lineage tree by taking advantage of upward and downward recursion [@doi:10.1109/TSP.2004.832006].

Viterbi follows from a upward recursion from leaf cells to the root, meaning we first define the values for the leaf cells and move to parent cells up to the root. We define $\delta$, an $N \times K$ matrix:

$$\delta (n,k) = \max\limits_{\bar{z}_{c(n)}}\{P(\bar{X}_n = \bar{x}_n, \bar{Z}_{c(n)} = \bar{z}_{c(n)} | z_n = j)\}$$
and the links between parent-daughter cells as:  
$$\delta_{p(n),n}(k) = \max\limits_{\bar{z}_n} \{P(\bar{X}_n = \bar{x}_n, \bar{Z}_n = \bar{z}_n | z_{p(n)} = j)\} = \max\limits_{j}\{\delta(n,j) T_{k,j}\}$$
So we initialize from the leaf cells as:  
$$\delta(n,k) = P(X_n = x_n | z_n = k) = EL(n,k)$$
and for non-leaf cells we have:  
$$\delta(n,k) =  \Big[\prod_{v \in c(n)} \delta_{n,v}(k)\Big]\times EL(n,k)$$
The probability of the optimal state tree corresponding to the observations tree, assuming root cell is noted as cell 1, is given by:
$$Z^* = \max\limits_{k}\{\delta(1,k) \pi_k \}$$
which arises from maximization over the conditional emission likelihood (EL) probabilities by factoring out the root cells as the outer maximizing step over all possible states.

#### Baum-Welch algorithm

In order to estimate the parameters corresponding to the hidden Markov models, Baum-Welch algorithm is used which employs the EM algorithm to find the maximum likelihood of the parameters. Here, we estimate $\theta = (\pi, T, p, a, s)$ the initial and transition probability matrices, the parameters of the observation distributions, namely Bernoulli parameter, shape, and scale parameter of Gamma distribution by maximizing the probability of the observations given the parameters; in other words $\theta^* = \max\limits_{\theta} P(X, Z|\theta)$, that is maximizing the joint probabilities.

$$ \xi_n(j,k) = P(z_n = j, z_{p(n)} = i | \bar{X}_1 = \bar{x}_1)$$
According to Bayes theorem, we can write the above probability in a joint form, and since $P(\bar{X}_1) = \bar{x}_1$ is the EL probabilities of the whole tree, it is just a constant coefficient and we can ignore it.  
So we could write it as:  
$$ \xi_n(j,k) = \frac{\beta(n+1, k) \times T_{j,k} \times \gamma_j(n)}{MSD(n+1, k) \times \beta_{p(n),n}(j)}$$
The maximum likelihood estimation of the initial probabilities:  
$$ \pi^*_k = \gamma_1(k)$$
The transition probability matrix would be estimated as:  
$$ T^*_{i,j} = \frac{\sum_{n=1}^{N-1} \xi_n(i,j)}{\sum_{n=1}^{N-1} \gamma_n(i)} $$

To estimate the distribution parameters after finding the most likely state for each cell, we group them and group their observations based on their estimated state and pass them to _StateDistribution_ class for maximum likelihood estimation. For estimating the Bernoulli parameter we simply find the sample mean of the observations for each state. Assuming we have $N_1$ data points estimated in state 1, the corresponding Bernoulli parameter for state 1 would be:

$$ p^*_1 = \frac{\sum_{i=1}^{N_1} x_b(i)}{N_1}$$
And for Gamma distribution parameters we use a closed-form estimation based on \cite{gamma_estimation} which has been corrected for bias:  
$$ a^* = \frac{N_1 \times  \sum_{i=1}^{N_1} x_g(i)}{\Big[N_1 \times \sum_{i=1}^{N_1} x_g(i) ln(x_g(i))\Big] - \sum_{i=1}^{N_1} ln(x_g(i)) \times \sum_{i=1}^{N_1} x_g(i)} $$
$$ s^* = \frac{1}{N_1^2} \times \Big[N_1 \times \sum_{i=1}^{N_1} x_g(i) ln(x_g(i)) - \sum_{i=1}^{N_1} ln(x_g(i)) \times \sum_{i=1}^{N_1} x_g(i) \Big]$$

### Synthetic lineage data

We generated synthetic lineage trees with $K$ discrete states and $N$ total number of cells for benchmarking. Lineages were composed of two primary data structures, the state and emissions trees. The state tree was randomly seeded with a root cell determined by the starting probabilities, then expanded by randomly sampling transitions based on the transition probability matrix. After creating the state tree with the desired number of cells, the emission tree is built upon it. Emissions were randomly sampled from the distributions for each cell’s state. Finally, the effects of the emissions were applied to the tree when necessary. If any cells died, their progeny were marked as unobserved by making their emissions NaN values. If applicable, the effects of finite-duration experiments were also applied. Cells existed outside of the experiment duration were similarly marked as unobserved, and those crossing the bounds of an experiment were marked as censored.

### Experimental single-cell lineage data

The data includes AU565 breast cancer cell line for control condition along with 7 concentrations of 2 types of targeted or chemotherapy compounds including lapatinib and gemcitabine. A fluorescent reporter was developed to translocate between the nucleus and cytoplasm to indicate the phase of the cells. Each cell is indicated as being in G1 or S/G2 phase according to the location of the reporter. When the reporter is located in the nucleus it means the cell is in G1 and when the reporter in the cytoplasm, the cell is passing through S/G2 phase. Each experiment lasts for 96 hours where the plates were being imaged every 30 minutes and each experiment was repeated three times. Single cells were manually tracked to collect cell fate in either phase or the amount of time it takes for each cell to pass through G1 and S/G2 phases.

#### Strategies to overcome model fitting to censored data

In single-cell experimental data collection, the lineages are almost never fully observed, in other words, we experience missing data for cells with time or fate censorship. Those leaf cells living at the end of the collected lineage trees, which may have been in their G1 or S/G2 exactly when the experiment was finished, experience a right-censorship, meaning, we have missing data from the future. For a cell that was in G1 at the end of the experiment, the time that the cell transitions to S/G2 is unknown, hence the cell's G1 is censored. In a similar way, almost all of the root cells appearing at the very beginning of the experiment are left-censored. This way, given a population of cells, we identify whether any of the cell's observations are censored or not. The uncensored values are passed to the estimator while the censored values will be handled by the survivor function. 
Another similar challenge is the unobserved measurements when cells die and their descendants disappear or when a leaf cell reaches the experiment end time while it is in the G1 phase such that the S/G2 phase for this cell is unobserved. We simply remove those measurements that have not been observed at all.

### Computational tools to explore the model

In this part we briefly mention the measures we used to monitor the goodness of the fit of the model. 

**AIC**  
In order to find the most likely number of states corresponding to the observations, Akaike Information Criterion (AIC) is used. This could be considered as an approach for model selection that could inform us of the most likely number of states, and also it deals with the trade off between over-fitting and under-fitting [@doi:10.1006/jmps.1999.1276].
Degrees of freedom: Our model estimate a $k \times 1$ initial probability matrix, a $k \times k$ transition matrix, and a $k \times m$ matrix of state-wise parameters where $k$ is the number of states and $m$ is the number of parameters associated with observation distributions. For the phase-specific observation sets we have a total of 6 parameters including 2 Bernoulli parameters and 2 pairs of shape and scale parameters for Gamma distribution. Since the row-sums for transition and initial probability matrices must be 1, these values are not independent. 
From distribution analysis of the phase lengths, we realized the shape parameter of the Gamma distribution remains fairly constant over different conditions, while the scale parameter changes. Removing the shape parameters of G1 and S/G2 for each states, instead of $k \times (k - 1) + (k - 1) + k \times (m)$ degrees of freedom, we will have $k \times (k - 1) + (k - 1) + k \times (m-2)$.

**Wasserstein distance**  
Wasserstein or Kantorovich–Rubinstein metric, is a measure of distance between two distributions. This metric was used to determine the difference between state emissions [@doi:10.1137/1118101]. When calculating the distance for a gamma distribution we used the analytical solution, the absolute value of the difference in distribution means.

### Model benchmarking

In this model, we use multivariate emission distributions to represent the physical characteristics of the cells within the lineages. To create our synthetic data we considered two possible options as our set of observations throughout an experiment. First, cell fate and cell lifetime, and second, phase-specific fate and time duration, for which we used Bernoulli and Gamma distributions. For the consistency of our model, we set a specific set of parameters for those mentioned distributions in each case. The following is the collection of distribution parameters for two-state synthetic data.

#### Phase non-specific observations
The parameters are reflective of fitting the model to data of 5 nM lapatinib treatment. Figures @fig:prop4, @fig:real_5, @fig:performUncenSingle, @fig:performUncenMulti, and @fig:performCenMulti are based on these parameters.

| State | Bern p | Shape | Scale |
| :---: |  :---: | :---: | :---: |
|State 1 | 0.99 | 8 | 6 |
| State 2 | 0.75 | 8 | 1 |


#### Phase specific observations
In Figures @fig:censor, @fig:performSyn, @fig:uncenSingle, @fig:uncenMulti, and @fig:cenMulti the data was created based on the following parameters. These parameters are based on estimations of 5 nM lapatinib treatment.

| State | Bern $G_1$ | Bern $G_2$ | Shape $G_1$ | Scale $G_1$ | Shape $G_2$ | Scale $G_2$ |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | 
| State 1 | 0.99 | 0.95 | 8 | 7 | 4 | 2 |
|State 2 | 0.95 | 0.9 | 6 | 4 | 3 | 5 |


#### Distant emissions

To create synthetic data with subpopulations of varying dissimilarity (Fig. @fig:wass), we use the phase-specific parameters set except that the values for the G1 phase Gamma shape parameter for state 1 is varied between $[4, 12]$. This results in an increase in the Wasserstein distance between the two cell states, allowing us to measure state assignment accuracy for different dissimilarity amounts between the two states.  
Likewise, for Figures @fig:wass1 and @fig:wass2, we used phase non-specific parameters and varied G1 phase Gamma scale parameter between $[1, 8]$ for state 1.

#### Emissions for AIC figures

Figure @fig:sAIC uses a unique set of values for the emissions matrix in order to simulate varying states for the AIC calculation. 


| State | Bern $G_1$ | Bern $G_2$ | Shape $G_1$ | Scale $G_1$ | Shape $G_2$ | Scale $G_2$ |
:---: | :---: | :---: | :---: | :---: | :---: | :---: | 
| State 1 | 0.99 | 0.9 | 10 | 2 | 10 | 2 |
|State 2 | 0.9 | 0.9 | 20 | 3 | 20 | 3 |
| State 3 | 0.85 | 0.9 | 30 | 4 | 30 | 4 |
| State 4 | 0.8 | 0.9 | 40 | 4 | 40 | 5 |

 